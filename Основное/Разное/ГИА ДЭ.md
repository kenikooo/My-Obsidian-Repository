— Перейти в [[HUB]] —
— Перейти к заданию [[КОД 09.02.06-1-2026 Том 1.pdf]] —

---
[[#Модуль 1. Настройка сетевой инфраструктуры]]
[[#Модуль 2. Организация сетевого администрирования]]
[[#Модуль 3. Эксплуатация объектов сетевой инфраструктуры]]

## Модуль 1. Настройка сетевой инфраструктуры
---
1. [[#Назначение имен]]
2. [[#Таблица адресации]]
3. [[#Настройка подинтерфейсов]]
4. [[#Создание GRE-Туннеля между HQ-RTR и BR-RTR]]
5. [[#Настройка OSPF]]
6. [[#Создание пользователей]]
7. [[#Настройка безопасного удаленного доступа]]
8. [[#Настройка протокола динамической конфигурации хостов для сети в сторону HQ-CLI]]
9. [[#Настройка BIND на HQ-SRV]]
10. [[#Настройка службы сетевого времени]]

---
### Назначение имен
Назначение имени:
```bash
hostnamectl set-hostname <name>.au-team.irpo;exec bash
```
### Таблица адресации:

| Устройство | Интерфейс            | IPv4          | Маска | VLAN | Подсеть       | Шлюз         |
| ---------- | -------------------- | ------------- | ----- | ---- | ------------- | ------------ |
| ISP        | ens18                | DHCP          | DHCP  | -    | DHCP          | DHCP         |
|            | ens19                | 172.16.1.1    | /28   | -    | 172.16.1.0    | -            |
|            | ens20                | 172.16.2.1    | /28   | -    | 172.16.2.0    | -            |
| HQ-RTR     | int0(to ISP)         | 172.16.1.2    |       |      | 172.16.1.0    | 172.16.1.1   |
|            | int1.100 (to HQ-SRV) | 192.168.10.1  | /27   | 100  | 192.168.10.0  | -            |
|            | int1.200 (to HQ-CLI) | 192.168.10.33 | /27   | 200  | 192.168.10.32 | -            |
|            | int1.999             | 192.168.10.65 | /29   | 999  | 192.168.10.64 | -            |
|            | Tunnel.0             | 10.0.0.1      | /30   | -    | 10.0.0.0      | -            |
| BR-RTR     | int0(to ISP)         | 172.16.2.2    | /28   | -    | 172.16.2.0    | 172.16.2.1   |
|            | int1 (to BR-SRV)     | 192.168.20.1  | /28   | -    | 192.168.20.0  | -            |
|            | Tunnel.0             | 10.0.0.2      | /30   | -    | 10.0.0.0      | -            |
| HQ-SRV     | ens18 (to HQ-RTR)    | 192.168.10.2  | /27   | 100  | 192.168.10.0  | 192.168.10.1 |
| BR-SRV     | ens18 (to BR-RTR)    | 192.168.20.2  | /28   | -    | 192.168.20.0  | 192.168.20.1 |
| HQ-CLI     | ens18 (to HQ-RTR)    | DHCP          | /27   | 200  | 192.168.10.32 | 192.168.10.3 |
### Настройка подинтерфейсов
На HQ-RTR.
Переходим к настройке интерфейса ``../enp0s8/options``:
```bash
TYPE=eth
BOOTPROTO=none
ONBOOT=yes
VLAN=yes
```
Создаем под интерфейс:
``mkdir /etc/net/ifaces/enp0s8.{10, 20, 99}``
Содержимое в ``../enp0s8.10/options``:
```bash
TYPE=vlan
ONBOOT=yes
BOOTPROTO=static
VID=10
HOST=enp0s8
```
Для остальных - аналогично, меняется только VID
Далее, для каждого подинтерфейса создаем файл `../enp0s8.10/ipv4address` и заполняем его.

На BR-RTR, BR-SRV, HQ-SRV, переходим в конфигурационный файл `../ИНТЕРФЕЙС/options`
```bash
TYPE=eth
BOOTPROTO=static
```
После чего, в той же директории, создаем `ipv4address` и заполняем его: `адрес/маска`, пример: `192.168.10.2/24`
### Создание GRE-Туннеля между HQ-RTR и BR-RTR:
```bash
mkdir -p /etc/net/ifaces/gre1 && cd !$
```
Создаем конфигурационный файл `options`:
```bash
BOOTPROTO=static
TYPE=iptun
TUNTYPE=gre
TUNLOCAL=<wan-ip-local> # Адрес в сторону ISP
TUNREMOTE=<wan-ip-remote> # Адрес в сторону ISP (соседа)
TUNTTL=64
TUNOPTION='ttl 64'
```
Назначаем адрес, создав конфигурационный файл `ipv4address`:
```bash
10.0.0.1/30 # для BR-RTR будет 10.0.0.2/30
```
Перезапускаем интерфейс:
```bash
systemctl restart network
```
### Настройка OSPF:
```bash
apt-get update && apt-get install frr -y
```
Редактируем файл демона:
```bash
vim /etc/frr/daemons
# Меняем только один параметр:
> ospfd=yes
```
Переходим в конфигурационный режим
```bash
vtysh
> config
```
Настройка GRE1, HQ-RTR и BR-RTR аналогично:
```bash
interfacce gre1
ip ospf authentication
ip ospf authentication-key P@ssw0rd
no ip ospf passive
exit
```
На HQ-RTR:
```bash
router ospf
ospf router-id 1.1.1.1
passive-interface default
network 10.0.0.0/30 area 0
network 192.168.10.0/27 area 0
network 192.168.10.32/27 area 0
network 192.168.10.64/29 area 0
exit
```
На BR-RTR:
```bash
router ospf
ospf router-id 2.2.2.2
passive-interface default
network 10.0.0.0/30 area 0
network 192.168.20.0/28
exit
```
### Создание пользователей
На HQ-SRV и BR-SRV:
```bash
# Создаем remote_user:
useradd -m remote_user -u 2026
passwd remote_user
# Создаем sshuser:
useradd -m sshuser -u 2026
passwd sshuser
echo "sshuser ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers
# Создаем net_admin:
useradd -m net_admin -s /bin/bash -u 2026
passwd net_admin
echo "net_admin ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers
```
### Настройка безопасного удаленного доступа
HQ-SRV и BR-SRV аналогично (раскоментируем и заменяем параметры):
```bash
vim /etc/openssh/sshd_config
> Port=2026
> AllowUsers sshuser # такого параметра нет, поэтому добавляем
> MaxAuthTries 2
> Banner /etc/openssh/banner
```
Создаем баннер:
```bash
vim /etc/openssh/banner
# Его содержимое:
Authorized access only
```
### Настройка протокола динамической конфигурации хостов для сети в сторону HQ-CLI
На HQ-RTR:
```bash
apt-get update && apt-get install dhcp-server
```
Переходим к конфигурации:
```bash
vim /etc/dhcp/dhcpd.conf
```
Содержимое `dhcpd.conf`
```bash
default-lease-time 600;
max-lease-time 7200
authoritative;

subnet 192.168.10.32 255.255.255.224 {
	range 192.168.10.34 192.168.10.64;
	option routers 192.168.10.33;
	option domain-name "au-team.irpo";
	option domain-name-server 192.168.10.2;
}
```
Меняем `DHCPDARGS`:
```bash
vim /etc/sysconfig/dhcpd
> DHCPDARGS="INT" # Указывается интерфейс идущий в сторону HQ-CLI
```
Запускаем службу:
```bash
systemctl enable --now dhcpd
```
### Настройка BIND на HQ-SRV
```bash
apt-get update && apt-get install bind
```
Создаем директорию для зон:
```bash
mkdir -p /etc/bind/zone
vim /etc/bind/zone/db.au-team.irpo
```
Содержимое `/etc/bind/zone/au-team.irpo`:
```bash
$TTL    86400 ;
@       IN      SOA     au-team.irpo. root.au-team.irpo. (
                          2024120101 ; Serial
                          3600       ; Refresh
                          1800       ; Retry
                          604800     ; Expire
                          86400 )    ; MinimumTTL

@       IN      NS      hq-srv.au-team.irpo.
        IN      A       192.168.10.2
hq-rtr  IN      A       192.168.10.1
        IN      A       192.168.10.33
	    IN      A       192.168.10.65
hq-cli  IN      A       192.168.10.34

br-srv  IN      A       192.168.20.2
br-rtr  IN      A       192.168.20.1

docker  IN      A       172.16.1.1
web     IN      A       172.16.2.1
```
Переходим к следующей зоне:
```bash
vim /etc/bind/zone/168.192.in-addr.arpa
```
Содержимое:
```bash
$TTL    86400
@       IN      SOA     au-team.irpo. root.au-team.irpo. (
                          2024120101 ; Serial
                          3600       ; Refresh
                          1800       ; Retry
                          604800     ; Expire
                          86400 )    ; Minimum TTL

        IN      NS      hq-srv.au-team.irpo.
1.1     IN      PTR     hq-srv.au-team.irpo.
10.2    IN      PTR     hq-rtr.au-team.irpo.
10.34   IN      PTR     hq-rtr.au-team.irpo.
20.2    IN      PTR     br-srv.au-team.irpo.
20.1    IN      PTR     br-rtr.au-team.irpo.
```
Конфигурируем основные файлы bind'а:
```bash
vim /etc/bind/local.conf
```
Содержимое /etc/bind/local.conf: 
```bash
zone "au-team.irpo" {
    type master;
    file "/etc/bind/zone/au-team.irpo";
};

zone "168.192.in-addr.arpa" {
    type master;
    file "/etc/bind/zone/168.192.in-addr.arpa";
};
```
Настраиваем DNS-пересылки:
```bash
vim /etc/bind/options.conf
```
Содержимое (просто подменяем/дополняем и расскоментируем нужное) `/etc/bind/options.conf`:
```bash
options {
    directory "/etc/bind/zone";

    recursion yes;
    allow-recursion { any; };
    
    forwarders {
        77.88.8.7;
        77.88.8.3;
        8.8.8.8;
    };
    forward only;
    
    listen-on { any; };
    allow-query { any; };
};
```
Проверка синтаксиса:
```bash
named-checkconf
# Перезапустим bind:
systemctl enable --now bind
systemctl restart bind
systemctl status bind # Если ошибок нет - все в норме
```
Настройка разрешения имен на самом сервере HQ-SRV:
```bash
vim /etc/resolv.conf
# Добавляем следующую строку:
nameserver 127.0.0.1
```
Проверка работоспособности:
```bash
nslookup hq-cli.au.team.irpo 127.0.0.1
host 192.168.10.2
# и т.д
```
На клиентах,  дополнение в resolv.conf будет выглядеть следующим образом:
```bash
nameserver 192.168.10.2
search au-team.irpo
```
### Настройка службы сетевого времени
Конфигурация на ISP
```bash
vim /etc/chrony.conf

server ntp0.ntp-servers.net iburst prefer minstratum 4
allow 0.0.0.0/0
local stratum 5
```
На всех остальных устройствах, меняем первую строку с pool:
```bash
server ISP-IP iburst
```
На каждом устройстве:
```bash
systemctl restart chronyd
chronyc sources # на клиентах
```
---
[[#Модуль 1. Настройка сетевой инфраструктуры]]
[[#Модуль 2. Организация сетевого администрирования]]
[[#Модуль 3. Эксплуатация объектов сетевой инфраструктуры]]

## Модуль 2. Организация сетевого администрирования
---
1. [[#Настройка контроллера домена Samba DC на BR-SRV]]
2. [[#Конфигурация файлового хранилища на HQ-SRV]]
3. [[#Настройка NFS-Server на HQ-SRV]]
4. [[#Настройка службы сетевого времени]]
5. [[#Конфигурация Ansible на BR-SRV]]
6. [[#Настраиваем Docker на BR-SRV]]
7. [[#Развертывания веб-приложения на HQ-SRV]]
8. [[#На маршрутизаторах конфигурируем статическую трансляцию портов]]
9. [[#Настройка обратного прокси на ISP]]
10. [[#Настройка web-based аутентификации на ISP]]
---
### Настройка контроллера домена Samba DC на BR-SRV:
```bash
apt-get update && apt-get install task-samba-dc -y
```
Очищаем базы и конфигурацию Samba:
```bash
rm -f /etc/samba/smb.conf
rm -rf /var/lib/samba/
rm -rf /var/cache/samba
mkdir -p /var/lib/samba/sysvol
```
Запускаем службу:
```bash
systemctl enable --now samba
```
Настраиваем Kerberos:
```bash
cp /var/lib/samba/private/krv5.conf /etc/krb5.conf
```
Перезапускаем службу:
```bash
systemctl start samba
```
После этого, проверяем Kerberos:
```bash
kinit administartor@AU-TEAM.IRPO
```
Когда билет получен (без ошибок), можем приступать к следующим шагам. Создадим группу HQ:
```bash
samba-tool group hq
```
После чего, создадим 5 пользователей:
```bash
for i in {1..5}; do
    samba-tool user create hquser$i 'P@ssw0rd'
    samba-tool group addmembers hq hquser$i
done
```
Ограничение набора команд (с hq-cli):
```bash
echo "%hq@au-team.irpo ALL=(root) /bin/cat, /bin/grep, /bin/id" >> /etc/sudoers
echo "%hq@au-team.irpo ALL=(root) !/bin/sh, !/bin/bash, !/usr/bin/sudo -i, !/usr/bin/sudo su" >> /etc/sudoers
```
Убедиться в том, что авторизация работает можно при помощи команды:
```bash
getent passwd hquser№
su - hquser№
```

### Конфигурация файлового хранилища на HQ-SRV
Создание RAID0
```bash
mdadm --create /dev/md0 --level=0 --raid-devices=2 /dev/sdb /dev/sdc
```
Сохраняем конфигурацию: 
```bash
mdadm --detail --scan >> /etc/mdadm.conf
update-initramfs -u
```
Создаем файловую систему ext4:
```bash
mkfs.ext4 /dev/md0
```
Монтируем:
```bash
mkdir -p /raid
vim /etc/fstab
> /dev/md0 /raid ext4 defaults 0 0
mount -a
```

### Настройка NFS-Server на HQ-SRV 
```bash
apt-get update && apt-get install nfs-server -y
```
Создаем папку
```bash
mkdir -p /raid/nfs
chmod 777 /raid/nfs
```
Затем, заходим в `/etc/exports` и добавляем следующую строку:
```bash
/raid/nfs 192.168.2.0/28(rw,sync,no_subtree_check,no_root_squash)
```
Применяем изменения:
```bash
exportfs -ra
```

### Настройка службы сетевого времени
Конфигурация на ISP
```bash
vim /etc/chrony.conf

server ntp0.ntp-servers.net iburst prefer minstratum 4
allow 0.0.0.0/0
local stratum 5
```
На всех остальных устройствах, меняем первую строку с pool:
```bash
server ISP-IP iburst
```
На каждом устройстве:
```bash
systemctl restart chronyd
chronyc sources # на клиентах
```

### Конфигурация Ansible на BR-SRV
```bash
apt-get update && apt-get install ansible -y
```
Переходим в рабочую директорию:
```bash
cd /etc/ansible/
```
В `ansible.cfg` расскоментируем и поменяем следующую строку:
```bash
inventory = /etc/ansible/hosts
```
Следующим файлом, который нам нужно заполнить `hosts`:
```bash
[all_hosts]
HQ-SRV ansible_host=192.168.1.10
HQ-CLI ansible_host=192.168.2.10
HQ-RTR ansible_host=192.168.1.1
BR-RTR ansible_host=192.168.3.1

[all:vars]
ansible_user=root
ansible_password=toor
ansible_python_interpreter=/usr/bin/python3
```
После чего, проверим:
```bash
ansible -m ping all
```
Если у вас по какой-либо из причин лезет `unreacheable` и жалуется на SSH. Заходим на каждое устройство и в файле /etc/openssh/sshd_config, раскоментируем и меняем следующее:
```bash
Port=22
PermitRootLogin=yes
PasswordAuthentication=yes
```
Перезапускаем службу:
```bash
systemctl restart sshd
```

### Настраиваем Docker на BR-SRV
```bash
apt-get update && apt-get install docker-engine docker-compose-v2
```
Примонтируем additional.iso:
```bash
mount /dev/sr0 /mnt
```
Создаем отдельную рабочую директорию:
```bash
mkdir -p /opt/webapp && cd !$
```
Импортируем docker-образ из tar-архива:
```bash
docker load -i /mnt/docker/mariadb_latest.tar
docker load -i /mnt/docker/site_latest.tar
```
Проверяем:
```bash
docker images
> Появятся mariadb 10.11 и site latest
```
Создаем и заходим в конфигурационный файл `docker-compose.yml`:
```bash
services:
	database:
		image: mariadb:10.11
		container_name: db
		restart: always
		environmnt:
			MARIADB_ROOT_PASSWORD: "toor"
			MARIADB_DATABASE: "testdb"
			MARIADB_USER: "testc"
			MARIADB_PASSWORD: "P@ssw0rd"
		ports:
		  - "3306:3306"
		    
	testapp:
		image: site:latest
		container_name: testapp
		restart: always
		environment:
			DB_TYPE: "maria"
			DB_HOST: "192.168.3.10" # BR-SRV
			DB_PORT: "3306"
			DB_NAME: "testdb"
			DB_USER: "testc"
			DB_PASS: "P@ssw0rd"
		ports:
		  - "8080:8000"
		depends_on:
		 - database
```
Запускаем контейнер:
```bash
docker compose up -d
```
Проверяем:
```bash
curl -I http://192.168.3.10:8080
```

### Развертывания веб-приложения на HQ-SRV
```bash
apt-get update && apt-get install lamp-server -y
```
Примонтируем additional.iso:
```bash
mount /dev/sr0 /mnt
```
Копируем файлы:
```bash
cp /mnt/web/index.php /var/www/html
cp /mnt/web/logo.png /var/www/html
```
Переходим в конфигурацию `index.php`:
```bash
vim /var/www/html/index.php
Меняем следующее (в начале):
$servername = "localhost";
$username = "webc";
$password = "P@ssw0rd";
$dbname = "webdb";
```
Запускаем службу:
```bash
systemctl enable --now httpd2 mariadb
```
Создаем БД, пользователя и выдаем ему права, требуемые по заданию:
```bash
mysql -u root -e "CREATE DATABASE webdb; CREATE USER 'web'@'localhost' IDENTIFIED BY 'P@ssw0rd'; GRANT ALL PRIVILEGES ON webdb.* TO 'web'@'localhost'; FLUSH PRIVILEGES;"
```
Импортируем схемы и данные из файла `dump.sql`:
```bash
mysql -u web -pP@ssw0rd webdb < /mnt/web/dump.sql
```
Меняем права к файлам:
```bash
chown apache2:apache2 /var/www/html/
```
Перезапускаем службы:
```bash
systemctl restart mariadb
systemctl restart httpd2
```

### На маршрутизаторах конфигурируем статическую трансляцию портов
Во время выполнения задания использовались ALT Linux, с установленным NFTables. Было произведено дополнение блока table `ip nat {`, HQ-RTR:
```bash
chain prerouting {
iif "enp7s1" tcp dport 8080 dnat to 192.168.1.10:8080 # Порт смотрящий на ISP, а адрес - HQ-SRV
iif "enp7s1" tcp dport 2026 dnat to 192.168.1.10:2026
}
```
BR-RTR:
```bash
chain prerouting {
iif "enp7s1" tcp dport 8080 dnat to 192.168.3.10:8080 # Порт смотрящий на ISP, а адрес - BR-SRV
iif "enp7s1" tcp dport 2026 dnat to 192.168.3.10:2026
}
```
После чего, перезапустим службу:
```bash
systemctl restart nftables
```

### Настройка обратного прокси на ISP
```bash
apt-get update && apt-get install nginx -y
```
Переходим в конфигурационный файл:
```bash
vim /etc/nginx/sites-available.d/default.conf
```
Содержимое `default.conf`
```bash
server {
	listen 80;
	server_name docker.au-team.irpo;
	
	location / {
		proxy_pass http://192.168.3.10:8080;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme
	}
}
server {
	listen 80;
	server_name web.au-team.irpo;
	
	location / {
		proxy_pass http://192.168.1.10:8080;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme
	}
}
```
Символическая ссылка к файлу:
```bash
ln -s /etc/nginx/sites-available.d/default.conf /etc/nginx/sites-enabled.d/
```
Запускаем службу:
```bash
systemctl enable --now nginx
```

### Настройка web-based аутентификации на ISP
```bash
apt-get update && apt-get install apache2-htpasswd -y
```
Создаем пользователя WEB, добавляем информацию о нем в файл и задаем пароль:
```bash
htpasswd –c /etc/nginx/.htpasswd WEB
```
Возвращаемся в конфигурационный файл `default.conf`:
```bash
vim /etc/nginx/sites-available.d/default.conf
```
И в блок `web.au-team.irpo`:
```bash
		...
		auth_basic "Restricted Area";
		auth_basic_user_file /etc/nginx/.htpasswd
	}
}
```
Перезапускаем службу:
```bash
systemctl restart nginx
```
---
[[#Модуль 1. Настройка сетевой инфраструктуры]]
[[#Модуль 2. Организация сетевого администрирования]]
[[#Модуль 3. Эксплуатация объектов сетевой инфраструктуры]]

## Модуль 3. Эксплуатация объектов сетевой инфраструктуры
---
1. [[#Импорт пользователей в домен на BR-SRV]]
2. [[#Настройка центра сертификации на базе HQ-SRV]]
3. [[#Настройка принт-сервера CUPS на HQ-SRV]]
4. [[#Настройка мониторинга устройств на HQ-SRV]]
5. [[#Ansible, написание playbook на BR-SRV]]
6. [[#Настройка Fail2ban на HQ-SRV]]
7. [[#Настройка Cyber-Backup]]
```txt
> В выполненном задании не описаны 3,4 и 6 пункты задания: перенастройка IP-туннеля, и настройка межсетевого экрана на маршрутизаторах. rsyslog (6 пункт)
```

---
### Импорт пользователей в домен на BR-SRV
Импорт пользователей с BR-SRV:
```bash
mount /dev/sr0 /mnt/
```
Пишем скрипт, для импорта `/root/import_users.sh:
```bash
#!/bin/bash
FILE="/mnt/Users.csv"

awk -F ';' 'NR>1 {print $5}' "$FILE" | sort | uniq | while read ou; do
    echo "Creating OU: $ou"
    samba-tool ou add "OU=$ou" --description="Imported OU" 2>/dev/null
done

tail -n +2 "$FILE" | while IFS=';' read -r fname lname role phone ou street zip city country password; do
    username=$(echo "${fname}.${lname}" | tr '[:upper:]' '[:lower:]' | tr -d ' ')

    echo "Import users: $username"
    samba-tool user create "$username" "$password" \
        --given-name="$fname" \
        --surname="$lname" \
        --job-title="$role" \
        --telephone-number="$phone" \
        --userou="OU=$ou" \
        --use-username-as-cn

    if [ $? -eq 0 ]; then
        samba-tool user setexpiry "$username" --noexpiry
    fi
done

```
- Запрос в Google, при котором найден скрипт: `импорт пользователей из файла /mnt/Users.csv при помощи samba tool`

Перед запуском скрипта, отключаем/меняем проверку сложности пароля:
```bash
samba-tool domain passwordsettings set --min-pwd-length=1 # Минимальная длина пароля - 1 символ
samba-tool domain passwordsettings set --complexity=off # Отключаем проверку сложности пароля 
```
Выдаем права на запуск для `import-users.sh`
```bash
chmod +x import-users.sh
```
### Настройка центра сертификации на базе HQ-SRV
```bash
apt-get update && apt-get install openssl-gost-engine -y
```
Включаем поддержку ГОСТ через control:
```bash
control openssl-gost enabled
```
Создаем закрытый ключ с алгоритмом ГОСТ-2012 (ca.key) и сертификат на 30 дней (ca.cer):
```bash
openssl genpkey -algorithm gost2012_256 -pkeyopt paramset:TCB -out ca.key
openssl req -new -x509 -md_gost12_256 -days 30 -key ca.key -out ca.cer 
```
После этого, создаем закрытые ключи по алгоритму ГОСТ веб-серверов:
```bash
# web.au-team.irpo
openssl genpkey -algorithm gost2012_256 -pkeyopt paramset:A -out web.au-team.irpo.key
# docker.au-team.irpo
openssl genpkey -algorithm gost2012_256 -pkeyopt paramset:A -out docker.au-team.irpo.key
# web.au-team.irpo (запросы на подпись ранее созданном УЦ):
openssl req -new  -md_gost12_256 -key gost.example.com.key -out web.au-team.irpo.csr
# docker.au-team.irpo (запросы на подпись ранее созданном УЦ):
openssl req -new  -md_gost12_256 -key gost.example.com.key -out docker.au-team.irpo.csr
```
Подписываем запрос в ранее созданном УЦ:
```bash
# web.au-team.irpo
openssl x509 -req -in web.au-team.irpo.csr -CA ca.cer -CAkey ca.key -CAcreateserial -out web.au-team.irpo.cer -days 30
# docker.au-team.irpo
openssl x509 -req -in docker.au-team.irpo.csr -CA ca.cer -CAkey ca.key -CAcreateserial -out docker.au-team.irpo.cer -days 30
```
Переходим к конфигурации на ISP, разрешаем доступ по SSH для пользователя `root`, чтобы можно было передать необходимые файлы `/etc/openssh/sshd_config`
```bash
PermitRootLogin yes
```
Перезапускаем службу:
```bash
systemctl restart sshd
```
Передаем необходимые файлы:
```bash
scp web.au-team.irpo.key root@172.16.1.1:~/
scp web.au-team.irpo.cer root@172.16.1.1:~/
scp docker.au-team.irpo.key root@172.16.1.1:~/
scp docker.au-team.irpo.cer root@172.16.1.1:~/
```
Создаем каталог и копируем туда файлы для ключей и сертификатов:
```bash
mkdir /etc/nginx/ssl
cp web.au-team.irpo.* /etc/nginx/ssl
cp docker.au-team.irpo.* /etc/nginx/ssl
```
Перенастроим доступ по https для доступа к сайту `web.au-team.irpo` и `docker.au-team.irpo`, переходим в конфигурационный файл `/etc/nginx/sites-available.d/default.conf`:
```nginx
server {
	listen 443 ssl;
	server_name docker.au-team.irpo;
	ssl_ceritificate /etc/nginx/ssl/web.au-taem.irpo.cer;
	ssl_certificate_key /etc/nginx/ssl/web.au-team.irpo.key;
	ssl_ciphers GOST2012-GOST8912-GOST8912:HIGH:MEDIUM;
	ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
	ssl_prefer_server_ciphers on;
	location / {
		proxy_pass http://172.16.2.2:8080;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme
	}
}
server {
	listen 443 ssl;
	server_name web.au-team.irpo;
	ssl_ceritificate /etc/nginx/ssl/web.au-taem.irpo.cer;
	ssl_certificate_key /etc/nginx/ssl/web.au-team.irpo.key;
	ssl_ciphers GOST2012-GOST8912-GOST8912:HIGH:MEDIUM;
	ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
	ssl_prefer_server_ciphers on;
	location / {
		proxy_pass http://172.16.1.2:8080;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme
	}
}
```
Проверяем на наличие ошибок:
```bash
nginx -t
```
Чтобы устранить следующую ошибку:
```nginx
nginx: [emerg] SSL_CTX_use_certificate("/etc/nginx/ssl/web.au-team.irpo.cer") failed (SSL: error:0300:SSL routines: :ee key too small)
```
Необходимо установить пакет с поддержкой ГОСТ:
```bash
apt-get update && apt-get install openssl-gost-engine -y
```
Включаем поддержку ГОСТ через control:
```bash
control openssl-gost enabled
```
Перезапускаем службу `nginx`:
```bash
systemctl restart nginx
```
После чего с HQ-SRV, передаем на HQ-CLI корневой сертификат УЦ:
```bash
scp ca.cer user@<IP_HQ-CLI>:~/
```
На HQ-CLI выполняем следующую команду:
```bash
cp /home/user/ca.cer /etc/pki/ca-trust/source/anchors/ && update-ca-trust
```
Проверить наличие сертификата можно перейдя в браузере `Настройки -> Управление сертификатами -> Центры сертификации`, там появится:
```bash
au-team.irpo
	hq-srv.au-team.irpo
```
При попытке подключиться к ресурсам, будет возникать ошибка `ERR_SSL_VERSION_OR_CIPHER_MISMATCH`, для решения требуется установить `КриптоПРО CSP`, поэтому переходим к ним на сайт:
```bash
https://cryptopro.ru
# Выбираем "Продукты", и жмем "Скачать КриптоПро CSP
# Вписываем ФИО, Почту (admin@au-team.irpo) и организацию (au-team.irpo), выбираем другой вариант (нам нужен RPM) и жмем "Скачать для Linux RPM"
```
После установки:
```bash
cd /home/user/Загрузки/linux-amd64
apt-get install -y cryptopro-preinstall
./install_gui.sh
```
После того, как откроется `Установщик КриптоПро CSP`, на первом шаге жмем "Далее", при выборе набора для установки, отмечаем `Импортировать корневые сертификаты из ОС`. И снова жмем "Далее" - Устанавливаем.
### Настройка принт-сервера CUPS на HQ-SRV
```bash
apt-get update && apt-get install cups cups-pdf -y
```
После установки, запускаем службу:
```bash
systemctl enable --now cups
```
В конфигурационном файле `/etc/cups/cupsd.conf`:
```c
Browsing On
Listen 0.0.0.0:631
<Location />
  Order allow,deny
  Allow all
</Location>
<Location /admin>
  Order allow,deny
  Allow all
</Location>
```
После этого, перезапускаем службу:
```bash
systemctl restart cups
```
Сам принтер, будет доступ с браузера, по следующей ссылке:
```bash
http://<IP_HQ-SRV>:631
```
Для добавления принтера и установки по умолчанию, с клиента, находим утилиту Printers, и в выпадающем окне жмем "Добавить", прописываем туда URL нашего принтера, и жмем далее. После добавления - ПКМ по принтеру и выбираем "Сделать по умолчанию".

### Настройка мониторинга устройств на HQ-SRV
```bash
apt-get update && apt-get install prometheus grafana prometheus-node_exporter -y
```
- На BR-SRV устанавливается только один дистрибутив: `prometheus-node_exporter`
Запускаем службы:
```bash
systemctl enable --now prometheus
```
Переходим в конфигурационный файл `/etc/prometheus/prometheus.yml`:
```yml
scrape_configs:
  - job_name: 'node_exporter'
    static_configs:
      - targets: ['localhost:9100', '<IP_BR-SRV>:9100']
```
Перезапускаем службу:
```bash
systemctl restart prometheus
```
После этого, запустим Grafana и сам Node-Exporter (он запускается на HQ и BR серверах):
```bash
# HQ-SRV
systemctl enable --now grafana-server prometheus-node_exporter
# BR-SRV
systemctl enable --now prometheus-node_exporter
```
Когда службы будут запущены, с клиента, заходим на сайт:
```bash
http://<IP_HQ-SRV>:9090
```
Данные для первого входа:
```bash
login: admin
password: admin
```
При первом входе, пароль потребуется сменить.
Когда вы попадете на сайт Grafan'ы, переходим во вкладку "Dashboards", создаем новый, и выбираем Import Dashboard, вписываем в импорт цифры `1860`(Node Exporter Full), чтобы получить уже готовый dashboard.

### Ansible, написание playbook на BR-SRV
```bash
apt-get update && apt-get install ansible -y
```
Примонтируем `Additional.iso`
```bash
mount /dev/sr0 /mnt
```
Подготовим окружение:
```bash
mkdir -p /etc/ansible/PC-INFO
```
Копируем playbook, из образа:
```bash
cp /mnt/playbook/<Название_файла_не_помню> /etc/ansible
```
Переходим в директорию Ansible:
```bash
cd /etc/ansible
```
Отредактируем инвентарный файлик `inventory.ini`:
```ini
[workstations]
HQ-SRV ansible_host=<IP_HQ-SRV>
HQ-CLI ansible_host=<IP_HQ-CLI>
```
После этого, заходим в редактирование того самого скопированного файла (там уже что-то готовенькое есть, поэтому просто дописываем пару строк):
```yml
---
- name: Inventory of machines
  hosts: workstations
  gather_facts: yes
  tasks:
    - name: Create inventory report
      delegate_to: localhost
      copy:
        dest: "/etc/ansible/PC-INFO/{{ ansible_hostname }}.yml"
        content: |
          Computer Name: {{ ansible_hostname }}
          IP Address: {{ ansible_default_ipv4.address }}
```
Запускаем:
```bash
ansible-playbook inventory_playbook.yml
```

### Настройка Fail2ban на HQ-SRV
```bash
apt-get update && apt-get install fail2ban
```
Делаем копию файлика для редактирования:
```bash
cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local
```
Переходим к конфигурации `/etc/fail2ban/jail.local` и находим блок `[sshd]`, их два - первый закомментирован, но нам нужен второй, находящийся ниже (он не закомментирован), из него убираем все, и пишем свое:
```bash
[sshd]
enabled = true
port = 2026 # или любой другой порт, если он отличается, если же порт стандартный (22), замените 2026 на true
filter = sshd
maxretry = 3
bantime = 60
backend = systemd
```
Запускаем службу:
```bash
systemctl enable --now fail2ban
```
Проверка статуса работы:
```bash
fail2ban-client status sshd
```

### Настройка Cyber-Backup
Все шаги будут происходить на HQ-SRV и HQ-CLI:
```bash
mkdir /cyber
cd !$
mount /dev/sr1 /cyber # на HQ-CLI, вместо /dev/sr1 будет /dev/sr0
./cyberbackup чет-там, табается
```
На сервере.. просто прожимаем далее.. далее, установить и так далее.
На клиенте, убираем Management Server (первая галочка), и ставим последнюю `Storage Node`, также по ходу установки нужно будет прописать IP_HQ-SRV и данные для входа:
```bash
login: root
password: toor
```
Для создания нового пользователя, сначала создадим его на HQ-SRV:
```bash
useradd irpoadmin
passwd irpoadmin # пароль назначаем P@ssw0rd 
```
После этого, на сайте КиберБэкапа, переходим в учетные записи, жмем "Добавить нового пользователя", пишем имя нашего юзера, выбираем - добавляем.
